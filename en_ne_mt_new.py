# -*- coding: utf-8 -*-
"""en_ne_MT_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-cCcQxiFbNWLiKi-P-GaA1JdR4z2uuF

#preprocessing
"""

!pip install pip==23.1

!pip install fairseq
!pip install subword-nmt
!pip install tensorboardX
!pip install transformers
!pip install sacremoses
!pip install sacrebleu

!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu118

!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113

!pip install fairseq==0.12.2

# !fairseq-preprocess --source-lang en --target-lang ne \
#     --trainpref /content/drive/MyDrive/new2/train.bpe --validpref /content/drive/MyDrive/new2/valid.bpe --testpref /content/drive/MyDrive/new2/test.bpe \
#     --destdir /content/drive/MyDrive/new2/data-bin --workers 20

# !fairseq-preprocess --source-lang en --target-lang ne \
#     --trainpref /content/drive/MyDrive/bpe/train.bpe --validpref /content/drive/MyDrive/bpe/valid.bpe \
#     --destdir /content/drive/MyDrive/bpe/data-bin --workers 20

!fairseq-preprocess --source-lang en --target-lang ne \
    --trainpref /content/drive/MyDrive/bpe/train.bpe --validpref /content/drive/MyDrive/bpe/valid.bpe --testpref /content/drive/MyDrive/bpe/test.bpe \
    --destdir /content/drive/MyDrive/bpe/data-bin --workers 20

fairseq-preprocess --source-lang en --target-lang ne \
    --trainpref /home/tto_lc/varsh/mt_new/train/train.bpe --validpref /home/tto_lc/varsh/mt_new/valid/valid.bpe --testpref /home/tto_lc/varsh/mt_new/test/test.bpe \
    --destdir /home/tto_lc/varsh/mt_new/databin --workers 20

# !fairseq-preprocess --source-lang en --target-lang ne \
#     --trainpref /content/mt/train.bpe --validpref /content/mt/valid.bpe --testpref /content/mt/test.bpe \
#     --destdir /content/mt/data-bin --workers 20 --srcdict /content/mt/spm.en.vocab --tgtdict /content/mt/spm.en.vocab


# !TEXT=/content/drive/MyDrive/mt
# !fairseq-preprocess --source-lang en --target-lang ne \
#     --trainpref /content/drive/MyDrive/mt/train.bpe --validpref /content/drive/MyDrive/mt/valid.bpe \
#     --joined-dictionary \
#     --destdir /content/drive/MyDrive/mt/data-bin \
#     --workers 20

# !fairseq-preprocess \
#     --source-lang en --target-lang ne \
#     --trainpref drive/MyDrive/mt_en_ne/mt/train.bpe \
#     --validpref drive/MyDrive/mt_en_ne/mt/valid.bpe \
#     --testpref drive/MyDrive/mt_en_ne/mt/test.bpe \
#     --destdir drive/MyDrive/mt_en_ne/mt/data-bin \
#     --workers 20 \
#     --bpe bert \
#     --tokenizer space \
#     --dataset-impl mmap \
#     --joined-dictionary \
#     --padding-factor 8

!CUDA_VISIBLE_DEVICES=0 fairseq-train /home/tto_lc/varsh/mt_new/databin \
    --arch transformer --share-decoder-input-output-embed \
    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \
    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \
    --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy \
    --label-smoothing 0.1 --max-tokens 4096 --update-freq 8 \
    --save-dir /home/tto_lc/varsh/mt_new/Checkpoints --log-format simple --log-interval 100 \
    --max-epoch 100

fairseq-train data-bin/eng-ne \
    --arch transformer --share-decoder-input-output-embed \
    --max-tokens 4096 \
    --optimizer adam --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 \
    --dropout 0.3 --weight-decay 0.0001 \
    --save-dir checkpoints --log-format simple --log-interval 100 \
    --max-epoch 20


# CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.en-ne \
#     --arch transformer_wmt_en_de_big --share-decoder-input-output-embed \
#     --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \
#     --lr 7e-4 --lr-scheduler inverse_sqrt --warmup-updates 8000 \
#     --dropout 0.2 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy \
#     --label-smoothing 0.1 --max-tokens 8192 --update-freq 16 \
#     --save-dir mt_new/Checkpoints \
#     --max-epoch 100 --fp16

# !CUDA_VISIBLE_DEVICES=0 fairseq-train \
#     /content/drive/MyDrive/mt_en_ne/mt/data-bin \
#     --arch transformer \
#     --optimizer adam \
#     --lr 1e-3 \
#     --lr-scheduler inverse_sqrt \
#     --warmup-updates 4000 \
#     --weight-decay 0.0001 \
#     --dropout 0.3 \
#     --max-tokens 4096 \
#     --criterion label_smoothed_cross_entropy \
#     --label-smoothing 0.1 \
#     --update-freq 2 \
#     --no-progress-bar \
#     --log-interval 100 \
#     --log-format simple \
#     --fp16 \
#     --tensorboard-logdir logs \
#     --save-dir drive/MyDrive/mt_en_ne/checkpoints \
#     --skip-invalid-size-inputs-valid-test \
#     --seed 42 \
#     --max-epoch 5

# Generate translations
# !fairseq-generate /content/drive/MyDrive/data-bin \
#     --path /content/drive/MyDrive/model.lstm_luong_wmt_en_de/checkpoint_best.pt \
#     --batch-size 128 --beam 5 --remove-bpe

!fairseq-generate /home/tto_lc/varsh/mt_new/databin \
    --path /home/tto_lc/varsh/mt_new/checkpoints/checkpoint_best.pt \
    --batch-size 128 --beam 5 --remove-bpe > /home/tto_lc/varsh/mt_new/gen_output1.txt

# !fairseq-interactive /content/mt1/data-bin --input /content/drive/MyDrive/new/test.bpe.en \
#     --path /content/checkpoints/checkpoint_best.pt \
#     --beam 5 --remove-bpe
# !fairseq-generate /content/drive/MyDrive/mt/data-bin --path /content/drive/MyDrive/checkpoints/checkpoint_best.pt \
#     --batch-size 128 --beam 5 --remove-bpe

# 024-07-22 02:14:16 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
# 2024-07-22 02:14:16 | INFO | fairseq_cli.generate | Translated 18,132 sentences (408,400 tokens) in 163.9s (110.64 sentences/s, 2492.11 tokens/s)
# Generate test with beam=5: BLEU4 = 6.86, 33.4/12.3/5.4/2.6 (BP=0.787, ratio=0.806, syslen=209608, reflen=259937)

!fairseq-interactive \
    --path /content/drive/MyDrive/Checkpoints/checkpoint_best.pt /content/drive/MyDrive/new2/data-bin \
    --beam 5 --source-lang en --target-lang ne \
    --tokenizer moses --remove-bpe

!sacrebleu -l en-as -i output.detok.txt -m bleu chrf ter --chrf-word-order 2

"""# Drive"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# Change 'your_data.zip' to the name of your uploaded file
with zipfile.ZipFile("/content/mt.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/mt")

